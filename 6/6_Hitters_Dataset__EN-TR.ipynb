{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0411a369-afff-4f30-bfde-7b2eb933e8bb",
   "metadata": {},
   "source": [
    "# **- Machine Learning -**\n",
    "# _* Ensemble Techniques *_\n",
    "## Hitters Data **:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48dff277-559a-4cd2-9338-fbbae357558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62a77c18-542b-4b37-8f62-0879317843f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "5      501   336     194      A        W      282      421      25   750.0   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "5           A  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Hitters_Data.csv')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd671a-c08d-4196-ac8b-0bd2893f568f",
   "metadata": {},
   "source": [
    "+ **Aşağıdaki KOD Bloğunda Sırası ile :**\n",
    "+ + Öncelikle **, 'y' (Target)** kolonunu LOGARİTMİK olarak atayalım **:**\n",
    "+ + Sonra **Numerik Olmayan (Kategorik Olan) Feature** kolonlarını **'get_dummies( )'** fonksiyonu ile **parçalayalım** ve **'binary'** şekilde **Numerik hale** getirelim. Yani **'dummy değişken'** hale getirelim. Bu numerik hale gelmiş hallerini de aşağıda yarattığımız **'dummies'** nesnesine **atayalım :**\n",
    "+ + Sonra da bu Kategorik Olan Feature kolonlarını ve ayrıca Target kolonunu Veri Setimizden **düşürelim** ve bu haliyle de **,** aşağıda yarattığımız **'X__'** nesnesine atayalım. Ve bu **'X__'** nesnesinin içindeki Feature kolonlarının tamamını **'float64' tipine dönüştürelim :**\n",
    "+ + En son da bu **Numerik hale gelen (dummies)** kolonlarından bize **gerekli olanları seçelim** ve **'concat( )'** fonksiyonunu kullanarak **diğer ('X__')** Feature kolonları ile **Birleştirelim.** Bu işlemin sonucunu da aşağıda yarattığımız **'X'** nesnesine **atayalım :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21a75e05-8730-4b8c-9079-335b8cd88e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(df.Salary)\n",
    "\n",
    "dummies = pd.get_dummies(df[['League' , 'Division' , 'NewLeague']])\n",
    "\n",
    "#   Drop the column with the independent variable (Salary), and columns for which we created dummy variables :\n",
    "#   Bağımsız değişkeni (Maaş) ve dummy (kukla) değişkenler oluşturduğumuz sütunları düşürün :\n",
    "X__ = df.drop(['Salary' , 'League' , 'Division' , 'NewLeague'] , axis = 1).astype('float64')\n",
    "\n",
    "#   Define the feature set X. :\n",
    "#   Feature kümesini tanımlayın :\n",
    "X = pd.concat([X__ , dummies[['League_N', 'Division_W', 'NewLeague_N']]] , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be3db9-7825-4221-99aa-45b50793fe22",
   "metadata": {},
   "source": [
    "+ Öncelikle aşağıda bir **'Regression'** uygulayacağız.\n",
    "<br> Aynı zamanda **'Regularization'** da yapacağız yani CEZALANDIRMA da yapacağız.\n",
    "<br> CEZALANDIRMA yapacağımız için de Veri Setini **'Standardize'** etmemiz gerekecek (**StandardScaler()**) **. :**\n",
    "<br> **++++ NOTE ++++**\n",
    "<br> Veri Setini **Standardize** ederken SADECE TRAIN Seti kullanmamız gerkiyor...\n",
    "<br> **'X_train'** ve **'X_test'** Setlerini de **,** bu **Standardize edilmiş** TRAIN Set üzerinden oluşturacağız..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbdabe93-dd8f-4e5b-b75c-80aee532e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Split data into training and test sets :\n",
    "#   Verileri TRAIN ve TEST setlerine ayırın :\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_trainStandard = scaler.transform(X_train)\n",
    "X_testStandard = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff4214-7c6c-448d-8b00-133a8883ad2e",
   "metadata": {},
   "source": [
    "**++++ CRUCIAL NOTE ++++**\n",
    "<br> Her şeyden önce **,** TRAIN Seti direkt **'Standardize'** ETMEYİP **,** ÖNCE **'Validation'**'u **AYIRIP , sonra 'Standardize'** EDİYORUZ...\n",
    "<br> Çünkü, ilk TRAIN Seti KOMPLE **'Standardize'** eder ve bu işlemden SONRA TRAIN Seti **'Validation'** Set için parçalarsak (*Yani **Standardize** etmeden önce **'Pipeline'** oluşturmaz isek **, 'Cross Validation'** DEFAULT olarak böyle yapar...*) model **,** **'Standardize'** ederken **'Validation'**'u da görmüş olur ve **yanlış - aldatıcı** bir model kurmuş oluruz...\n",
    "\n",
    "``Bundan dolayı ; ÖNCE 'Validation' Set'i ayıracağız , SONRA 'Standardize' edeceğiz...``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22273a62-1572-4ba2-9dbd-483b013bd1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "{'Regressor__max_features': 3, 'Regressor__n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "regressor = RandomForestRegressor(random_state=0)\n",
    "\n",
    "#   Number of Trees in random forest :\n",
    "n_estimators = [100 , 200 , 300 , 400 , 500 , 600]\n",
    "\n",
    "#   Number of features at every 'split' :\n",
    "max_features = [3 , 4 , 5 , 6 , 7]\n",
    "\n",
    "#   Create grid :\n",
    "params = {\n",
    " 'Regressor__n_estimators': n_estimators,\n",
    " 'Regressor__max_features': max_features,\n",
    " }\n",
    "\n",
    "pipe = Pipeline([('scaler', preprocessing.StandardScaler()) , ('Regressor', regressor)])\n",
    "\n",
    "#   Random search of parameters :\n",
    "#   EN İYİ Parametrelerin RASTGELE Search edilmesi (aranması) :\n",
    "clf_grid = GridSearchCV(estimator=pipe , param_grid=params, \n",
    "                                cv=5 , verbose=2 , scoring='neg_mean_squared_error' , n_jobs= -1)\n",
    "#   Fit the model :\n",
    "clf_grid.fit(X_train , y_train)\n",
    "#   Print results :\n",
    "print(clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5f20a-3eb6-456f-8123-3c7444add2ff",
   "metadata": {},
   "source": [
    "**Yukarıdaki KOD Bloğunda olanlar :**\n",
    "+ **``'GridSearchCV'`` modülü SIRASI ile :**\n",
    "+ + Bir kombinasyonu alıyor. (Mesela ilk önce yukarıdaki **'100'e 3'** kombinasyonu olsun)... **'GridSearchCV' ,** içerisindeki **'(cv=5)'** parametresinden dolayı **'5-Fold Cross Validation'** yapması gerektiğini biliyor... Yani öncelikle TRAIN Veri Setini **'5'** parçaya bölmesi gerektiğini biliyor... Ve RASTGELE bir parçasını **'Validation'** Set olarak BİR KENARA AYIRIYOR.\n",
    "+ + Şimdi bu ayırma işleminden sonra **,** Parametreleri SET etmem lazım diyor. Peki neyin Parametrelerini SET etmem lazım diyor **? 'Pipe'**'nin Parametrelerini SET etmem lazım diyor (**estimator=pipe**)...\n",
    "+ + **'Pipe'**'ye geliyor... Şimdi **'Validation'** Set ayrıldıktan sonra ki geriye kalan TRAIN Sette **; ilk seçilen Parametre Kombinasyonunu (100'e 3)** FIT etme işlemini başlatıyor...\n",
    "+ + **'Pipe'**'ın **,** öncelikle **'scaler'** işlemini yapmasını istiyor. Yani **Standardizasyon** işlemini bu aşamada gerçekleştiriyor... SONRA da **'Regressor'** Tekniğini kullanmasını istiyor. **'Regressor'**'a baktığımızda da **RandomForestRegressor()** Tekniğini kullanacağımızı görüyoruz...\n",
    "+ + Şimdi de **'n_estimators'** ve **'max_features'** parametrelerimizin olası değerlerini SET etmemiz gerekiyor **(param_grid=params)**...\n",
    "<br> KOD Bloğunda bu parametrelerin başlarına **'Regressor__'** koymamızın sebebi de **:**\n",
    "<br> Çünkü bir PIPELINE yolluyoruz **,** ama bu Parametrelerin kime ait olduğunu bilmiyoruz... Yani PIPELINE'nin içerisindeki **'scaler'**'e mi ait yoksa **'Regressor'**'a mı ait bilmiyoruz... Ve **Regressor**'a ait Parametreler olduğunu bilmek için de başlarına **'Regressor__'** yazıyoruz...\n",
    "<br> Böyle yazınca da **, 'RandomForestRegressor'**'a ait olan Parametreleri değiştirmesi gerektiğini biliyor...\n",
    "+ + **'GridSearchCV' ,** her bir **Kombinasyon** için **'5'** farklı Validation Seti ayırıp (**5_Fold**) **;** bu her ayrım için **,** bu işlemleri en baştan tekrar ediyor ve sonra **yeni Kombinasyona** geçiyor (Mesela **100'e 4**)...\n",
    "\n",
    "+ + GRID'i FIT ederken de Orijinal **'X_train'** ve **'y_train'** Setleri kullanıyoruz...\n",
    "\n",
    "#### **++++ CRUCIAL NOTE ++++**\n",
    "Yukarıda **,** PIPELINE içerisinde hem **'scaler'** hem de **'Regressor'** Teknikleri olduğu için **;** Sözlük türünde oluşturduğumuz Parametrelerin isimlerine direkt **\"'n_estimators'\"** ve **\"'max_features'\"** yazamıyoruz... PIPELINE içindeki **hangi** Tekniğe ait ise **,** onun ismini de MUHAKKAK belirtmemiz gerekiyor...\n",
    "<br> **\"'Regressor__n_estimators'\"** ve **\"'Regressor__max_features'\"** ... gibi ...\n",
    "\n",
    "+ Şimdi de EN İYİ Parametreleri bulduktan sonra EN BAŞTAN Modelimizi FIT ediyoruz... Ama artık burada **Standardize edilmiş 'X' TRAIN** Seti kullanmamız lazım...\n",
    "<br> Daha sonra da yine **, ona göre Standardize edilmiş 'X' TEST** Setinde **Tahminleme** yapacağız **:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88836938-3e4c-495a-9354-fe6154b34c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.15424688036594958\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=0 , n_estimators=300 , max_features=3)\n",
    "\n",
    "clf.fit(X_trainStandard , y_train)\n",
    "\n",
    "y_pred = clf.predict(X_testStandard)\n",
    "\n",
    "print('Mean Squared Error:' , mean_squared_error(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cde8dad6-8446-45da-a09d-72bc20ff3be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293631151955395"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da96796-b5a4-4934-b147-af803f640720",
   "metadata": {},
   "source": [
    "+ Şimdi de **bir sürü Teknik** kullanalım ve her bir Tekniğin de farklı parametrelerini kullanarak deneyelim **:**\n",
    "\n",
    "**+--- NOTE ---> 'Pipeline( )'** içerisine muhakkak bir Teknik göndermemiz lazım **!** Aşağıda **'RandomForestRegressor()'** tekniğini gönderiyoruz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20158091-5476-414d-b122-6e64cd53338c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=3, n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    Create a PIPELINE :\n",
    "pipe = Pipeline([('scaler', preprocessing.StandardScaler()) , ('Regressor', RandomForestRegressor())])\n",
    "\n",
    "#   Create space of candidate learning algorithms and their hyperparameters :\n",
    "search_space = [ { 'Regressor': [Ridge()] , 'Regressor__alpha': np.logspace(-3, 1, 10) } ,\n",
    "                 { 'Regressor': [Lasso(max_iter=10000)] , 'Regressor__alpha': np.logspace(-3, 1, 10) } ,\n",
    "                 { 'Regressor': [KNeighborsRegressor()] , 'Regressor__n_neighbors':[2, 3, 4, 5, 6] } ,\n",
    "                 { 'Regressor': [RandomForestRegressor(random_state=0)] ,\n",
    "                                'Regressor__n_estimators': [100, 200, 300, 400, 500] ,\n",
    "                                'Regressor__max_features': [3, 4, 5, 6, 7] } ]\n",
    "\n",
    "#   Create grid search :\n",
    "clf = GridSearchCV(pipe , search_space , cv=5 , verbose=0 , scoring='neg_mean_squared_error')\n",
    "#   Fit grid search :\n",
    "best_model = clf.fit(X_train , y_train)\n",
    "#   View best model :\n",
    "best_model.best_estimator_.get_params()['Regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330cfb2d-7005-421d-8d80-dfa7b5496d8c",
   "metadata": {},
   "source": [
    "**YUKARIDA :**\n",
    "+ + **GridSearchCV** modülü ile **; Pipeline (pipe)**'yi **, 'search_space'** atamasının içerisinde gezdirerek **, Pipeline** içerisinde oluşturduğumuz **\"'Regressor' : RandomForestRegressor()\" Tekniğini** her REPEAT'de **, 'search_space'** atamasının içerisindeki **Teknikler** ile değiştirebiliyoruz...\n",
    "+ + Yani **'search_space'** atamasının içerisindeki HER BİR **Tekniği , 'Pipeline'** içerisinde deneyebiliyoruz...\n",
    "\n",
    "**+--- NOTE --->** Yukarıda gördüğümüz gibi **, 'search_space'** atamasının içerisindeki Tekniklerle birlikte Parametreleri de var...\n",
    "<br> **+--- NOTE --->** Daha yukarıda yaptığımız işlemlerin her birini **;** şimdi de **,** her bir Tekniği AYRI AYRI kullanarak yapacak... Ve En ideal Tekniği VE o Tekniğin En İyi Parametrelerini bize döndürecek...\n",
    "\n",
    "+ Yukarıda gördüğümüz gibi **,** En İyi Tekniğimiz **'RandomForestRegressor'** imiş. Bu Tekniğin En İyi Parametreleri de **'max_features=3'** ve  **'n_estimators=300'** imiş... **:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a4effb8-5ae1-4fd0-ae79-9864a42f07e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.15424688036594958\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=0 , n_estimators=300 , max_features=3)\n",
    "\n",
    "#   Train the model using the training sets : \n",
    "#   Modeli , TRAINING Setlerini kullanarak eğitin : ( y_pred = clf.predict(X_test) )\n",
    "\n",
    "clf.fit(X_trainStandard , y_train)\n",
    "\n",
    "y_pred = clf.predict(X_testStandard)\n",
    "\n",
    "print('Mean Squared Error:' , mean_squared_error(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c284c1d-0bf3-4c6f-89d9-c244a7e1232b",
   "metadata": {},
   "source": [
    "**++++ CRITICAL NOTE ++++**\n",
    "+ Yukarıdaki Son 2 KOD Bloğu ile **;** Şimdiye kadar öğrendiğimiz hemen hemen her şeyi kullanmış olduk...\n",
    "+ ANCAK **!** Ne kadar çok Tekniği bir arada denersek **,** yine OVERFITTING ihtimalini arttırmış oluruz **...!**\n",
    "+ Aynı zamanda TESADÜFİ olarak bir Tekniğin herhangi bir Parametresi **,** Veri Setine çok iyi denk gelmiş olabilir yani çok iyi oturmuş olabilir ve bizi yine bu şekilde aldatabilir... Böyle olduğu için de **,** GERÇEK Hayatta denediğimizde bizi hayal kırıklığına uğratabilir...\n",
    "+ Yani daha çok Teknik ve Parametre denedikçe **, 'Type-1' Error**'u arttırabiliriz..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
